# =============================================================================
# MedAgentBench Environment Configuration
# =============================================================================
# Copy this file to .env and fill in the values

# Required: OpenAI API key for the purple agent (LLM)
OPENAI_API_KEY=your_openai_api_key_here

# Required: LLM model identifier in LiteLLM format
# Supports any model available via litellm
MEDAGENT_LLM_MODEL=openai/gpt-4o-mini

# =============================================================================
# Service URLs (must be running for evaluation)
# =============================================================================

# Required: FHIR Server URL
# Used by: MCP server (for FHIR API calls), Evaluator (for verification)
# Start with: docker run -p 8080:8080 jyxsu6/medagentbench:latest
MCP_FHIR_API_BASE=http://localhost:8080/fhir/

# Required: MCP Server URL
# Used by: Evaluator (fetches tasks/prompts), Agent (tool calls)
# Start with: uv run python -m src.mcp.server
MCP_SERVER_URL=http://localhost:8002

# =============================================================================
# Output Configuration
# =============================================================================

# Required: Output directory for evaluation results
MEDAGENT_OUTPUT_DIR=outputs/medagentbench

# =============================================================================
# Optional: MCP Server Resource Paths (use bundled defaults if not set)
# =============================================================================

# Optional: Path to tasks JSON file (for MCP server)
# Default: src/mcp/resources/tasks/tasks.json
# MCP_TASKS_FILE=src/mcp/resources/tasks/tasks.json

# Optional: Path to system prompt file (for MCP server)
# Default: src/mcp/resources/prompts/system_prompt.txt
# MCP_SYSTEM_PROMPT_FILE=src/mcp/resources/prompts/system_prompt.txt

